{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6db2ccf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and preprocess\n",
    "df = pd.read_csv('../data/car_data.csv')\n",
    "df4 = pd.read_csv('../data/car_data4.csv')\n",
    "df = pd.concat([df4, df], ignore_index=True)\n",
    "\n",
    "df['model'] = df['name'].apply(lambda x: ' '.join(x.split()[1:]))\n",
    "df['car_age'] = 2025 - df['year']\n",
    "df.drop(['Unnamed: 0', 'name', 'year'], axis=1, inplace=True)\n",
    "\n",
    "for col in ['company', 'fuel_type', 'model']:\n",
    "    df[col] = df[col].astype('category')\n",
    "    df[col + '_cat'] = df[col].cat.codes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ccbb1eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize features\n",
    "scaler_x = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "features = df[['car_age', 'kms_driven', 'company_cat', 'fuel_type_cat', 'model_cat']].values\n",
    "target = df['Price'].values.reshape(-1, 1)\n",
    "\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "features_scaled = scaler_X.fit_transform(features)\n",
    "target_scaled = scaler_y.fit_transform(target.reshape(-1, 1)).flatten()\n",
    "# Create sequences\n",
    "seq_len, pred_len = 36, 12\n",
    "# Create sequences with scaled data\n",
    "X, y = [], []\n",
    "for i in range(len(features_scaled) - seq_len - pred_len):\n",
    "    X.append(features_scaled[i:i+seq_len])\n",
    "    y.append(target_scaled[i+seq_len:i+seq_len+pred_len])\n",
    "\n",
    "X = np.array(X)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "614abe93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CarPriceDataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, X, y):\n",
    "        self.X = torch.tensor(X, dtype=torch.float32)\n",
    "        self.y = torch.tensor(y, dtype=torch.float32)\n",
    "\n",
    "    def __len__(self): return len(self.X)\n",
    "    def __getitem__(self, idx): return self.X[idx], self.y[idx]\n",
    "\n",
    "split = int(0.8 * len(X))\n",
    "train_ds = CarPriceDataset(X[:split], y[:split])\n",
    "test_ds = CarPriceDataset(X[split:], y[split:])\n",
    "train_dl = DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9870e121",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, d_model, max_len=100):\n",
    "        super().__init__()\n",
    "        pos = torch.arange(0, max_len).unsqueeze(1)\n",
    "        div = torch.exp(torch.arange(0, d_model, 2) * (-np.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(max_len, d_model)\n",
    "        pe[:, 0::2] = torch.sin(pos * div)\n",
    "        pe[:, 1::2] = torch.cos(pos * div)\n",
    "        self.pe = pe.unsqueeze(0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x + self.pe[:, :x.size(1)].to(x.device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "608d444c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CrossformerBlock(nn.Module):\n",
    "    def __init__(self, d_model, n_heads, d_ff, dropout):\n",
    "        super().__init__()\n",
    "        self.attn = nn.MultiheadAttention(d_model, n_heads, batch_first=True, dropout=dropout)\n",
    "        self.ff = nn.Sequential(\n",
    "            nn.Linear(d_model, d_ff), nn.ReLU(), nn.Dropout(dropout),\n",
    "            nn.Linear(d_ff, d_model)\n",
    "        )\n",
    "        self.norm1 = nn.LayerNorm(d_model)\n",
    "        self.norm2 = nn.LayerNorm(d_model)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x2, _ = self.attn(x, x, x)\n",
    "        x = self.norm1(x + x2)\n",
    "        x2 = self.ff(x)\n",
    "        return self.norm2(x + x2)\n",
    "\n",
    "class Crossformer(nn.Module):\n",
    "    def __init__(self, input_dim, d_model=128, n_heads=4, d_ff=256, num_layers=3, pred_len=12, dropout=0.1):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(input_dim, d_model)\n",
    "        self.pos_enc = PositionalEncoding(d_model)\n",
    "        self.encoder = nn.Sequential(*[CrossformerBlock(d_model, n_heads, d_ff, dropout) for _ in range(num_layers)])\n",
    "        self.regressor = nn.Sequential(\n",
    "            nn.Linear(d_model, 64), nn.ReLU(),\n",
    "            nn.Dropout(dropout), nn.Linear(64, pred_len)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.input_proj(x)\n",
    "        x = self.pos_enc(x)\n",
    "        x = self.encoder(x)\n",
    "        x = x.mean(dim=1)  # Global pooling\n",
    "        return self.regressor(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4c2c89f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 0.3666, Val Loss: 0.4488\n",
      "Epoch 2, Train Loss: 0.3637, Val Loss: 0.4609\n",
      "Epoch 3, Train Loss: 0.3613, Val Loss: 0.4411\n",
      "Epoch 4, Train Loss: 0.3585, Val Loss: 0.4369\n",
      "Epoch 5, Train Loss: 0.3548, Val Loss: 0.4327\n",
      "Epoch 6, Train Loss: 0.3514, Val Loss: 0.4517\n",
      "Epoch 7, Train Loss: 0.3463, Val Loss: 0.4298\n",
      "Epoch 8, Train Loss: 0.3421, Val Loss: 0.4422\n",
      "Epoch 9, Train Loss: 0.3384, Val Loss: 0.4626\n",
      "Epoch 10, Train Loss: 0.3356, Val Loss: 0.4389\n",
      "Epoch 11, Train Loss: 0.3325, Val Loss: 0.4643\n",
      "Epoch 12, Train Loss: 0.3312, Val Loss: 0.4520\n",
      "Epoch 13, Train Loss: 0.3294, Val Loss: 0.4512\n",
      "Epoch 14, Train Loss: 0.3272, Val Loss: 0.4628\n",
      "Epoch 15, Train Loss: 0.3253, Val Loss: 0.4620\n",
      "Early stopping.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = Crossformer(input_dim=X.shape[2]).to(device)\n",
    "criterion = nn.HuberLoss()\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=5e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.7)\n",
    "\n",
    "epochs = 50\n",
    "best_loss = float('inf')\n",
    "patience, wait = 7, 0\n",
    "\n",
    "for ep in range(epochs):\n",
    "    model.train()\n",
    "    loss_sum = 0\n",
    "    for xb, yb in train_dl:\n",
    "        xb, yb = xb.to(device), yb.to(device)\n",
    "        pred = model(xb)\n",
    "        loss = criterion(pred, yb)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        loss_sum += loss.item()\n",
    "\n",
    "    val_loss = 0\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for xb, yb in test_dl:\n",
    "            xb, yb = xb.to(device), yb.to(device)\n",
    "            pred = model(xb)\n",
    "            val_loss += criterion(pred, yb).item()\n",
    "\n",
    "    scheduler.step()\n",
    "    val_loss /= len(test_dl)\n",
    "    print(f\"Epoch {ep+1}, Train Loss: {loss_sum/len(train_dl):.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        wait = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pt')\n",
    "    else:\n",
    "        wait += 1\n",
    "        if wait > patience:\n",
    "            print(\"Early stopping.\")\n",
    "            break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "51dbf276",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE: 307005.59, RMSE: 437809.94, R²: -0.04\n"
     ]
    }
   ],
   "source": [
    "model.load_state_dict(torch.load('best_model.pt'))\n",
    "model.eval()\n",
    "y_true, y_pred = [], []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for xb, yb in test_dl:\n",
    "        xb = xb.to(device)\n",
    "        pred = model(xb).cpu().numpy()\n",
    "        y_true.append(yb.numpy())\n",
    "        y_pred.append(pred)\n",
    "\n",
    "y_true = scaler_y.inverse_transform(np.concatenate(y_true))\n",
    "y_pred = scaler_y.inverse_transform(np.concatenate(y_pred))\n",
    "\n",
    "mae = mean_absolute_error(y_true, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y_true, y_pred))\n",
    "r2 = r2_score(y_true, y_pred)\n",
    "print(f\"MAE: {mae:.2f}, RMSE: {rmse:.2f}, R²: {r2:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "65787509",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), '../models/crossformer_model.pt')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
